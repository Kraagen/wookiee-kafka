{"name":"Wookiee-kafka","tagline":"Kafka support component for Wookiee","body":"# Wookiee - Component: Kafka\r\n\r\n[![Build Status](https://travis-ci.org/Webtrends/wookiee-kafka.svg?branch=master)](https://travis-ci.org/Webtrends/wookiee-kafka) [![Coverage Status](https://coveralls.io/repos/Webtrends/wookiee-kafka/badge.svg?branch=master&service=github)](https://coveralls.io/github/Webtrends/wookiee-kafka?branch=master) [![Latest Release](https://img.shields.io/github/release/webtrends/wookiee-kafka.svg)](https://github.com/Webtrends/wookiee-kafka/releases) [![License](http://img.shields.io/:license-Apache%202-red.svg)](http://www.apache.org/licenses/LICENSE-2.0.txt)\r\n\r\n[Main Wookiee Project](https://github.com/Webtrends/wookiee)\r\n\r\nFor Configuration information see [Kafka Config](docs/config.md)\r\n\r\nThe kafka component allows users to set up a Worker which can be replicated and consumes from a Kafka topic. It is also capable of coordinating multiple other Nodes (via Zookeeper) to share the load of topic consumption. In other words, this component allows one to create a horizontally scalable kafka consumer app with ease.\r\n\r\n### PartitionConsumerWorker\r\n\r\nThis is the most important class and will have to be overridden, create a class of your own that extends it within your app. Then override the function:\r\n```\r\n    def onReceive(messageResponse: MessageResponse) {}\r\n```\r\nThis method will actually handle the event consumed from Kafka and process it in the way your app sees fit.\r\n\r\n### Configuration\r\n\r\n# Base\r\nBase configuration is simple, when not using a producer or consumer all one needs to provide is an app-name\r\n```json\r\nwookiee-kafka {\r\n    app-name = \"test\"\r\n}\r\n```\r\n\r\n# Consumer\r\nIf one would like to utilize horizontally scalable consumers, then set these properties and\r\noverride the onReceive(messageResponse: MessageResponse) method in PartitionConsumerWorker.scala\r\n```json\r\nwookiee-kafka {\r\n    app-name = \"test\"\r\n    worker-class = \"com.product.code.CustomWorker\"\r\n    zk-offset-commit-rate-millis = 500\r\n    consumer {\r\n      topics = [\r\n        {\r\n          name = \"Lab_G_scsRawHits\"\r\n          event-age-threshold-seconds = 90\r\n        },\r\n        {\r\n          name = \"Lab_G_dcRawHits\"\r\n          event-age-threshold-seconds = 0\r\n        }\r\n      ]\r\n\r\n      kafka-hosts = [\r\n        {\r\n          \"id\": \"cluster1\"\r\n          \"brokers\": [\"server1.com\",\"server2.com\"]\r\n        },\r\n        {\r\n          \"id\": \"cluster2\"\r\n          \"brokers\": [\"2server1.com\"]\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\nOne will also need to pull in the wookiee-zookeeper component and configure it like so\r\n```json\r\nwookiee-zookeeper {\r\n  datacenter = \"Lab\"\r\n  pod = \"Tests\"\r\n  quorum = \"zoo01.keeper.org\"\r\n  session-timeout = 30s\r\n  connection-timeout = 30s\r\n  retry-sleep = 5s\r\n  retry-count = 150\r\n  base-path = \"/discovery/clusters\"\r\n\r\n  message-processor {\r\n    # How often the MessageProcessor should share it's subscription information\r\n    share-interval = 1s\r\n    # When should MessageTopicProcessor instances be removed after there are no longer any subscribers for that topic\r\n    trash-interval = 30s\r\n    # The default send timeout\r\n    default-send-timeout = 2s\r\n  }\r\n}\r\n```\r\n\r\n# Producer\r\nIf one would like to write to a set of Kafka brokers then configure the producers like so\r\n```json\r\nwookiee-kafka {\r\n    app-name = \"test\"\r\n\r\n    producer {\r\n      producer.type=\"sync\"\r\n      metadata.broker.list=\"broker1.com:9092,broker2.com:9092\"\r\n      request.required.acks=1\r\n      queue.time=5000\r\n      queue.size=10000\r\n      batch.size=200\r\n      compression.codec=\"gzip\"\r\n    }\r\n}\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}